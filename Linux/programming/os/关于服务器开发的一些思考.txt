Linux服务器（标准套接口）开发的网络架构（网络模型）：我们将以TCP为准介绍。



并发引发了两个问题：
	1 阻塞非阻塞（从单线程的角度看待并发）：从宏观上以read/write为例认识，在阻塞时，read到空缓冲区时会进入waiting状态，但是非阻塞时，read到空缓冲区时会返回，从微观上看即是陷阱机制，不管是微观还是宏观，本质一致；
	2 同步异步（从多线程的角度看待并发）：首先要认识到异步是随机是无序，其次异步发生在多线程的情况，因为多线程的并发而引发了公共数据区的争用，继而才产生了同步问题（发生异步现象，需要采用同步方法解决）。



常见IO模型（五种）：
	阻塞IO   非阻塞IO   ：   阻塞非阻塞可以针对单次IO，也可以针对某个fd
	信号驱动IO（理解信号的底层机制）   异步IO（IO和数据处理分离）   IO多路复用（select poll epoll）



常见的服务器类型：
	点对点类型服务器（实际上这根本不能叫做服务器，一般用来写测试）：
		只能处理一个fd的一次IO事件的单线程服务器、只能处理一个fd的多个IO事件的循环读写服务器（这种服务器的close不会在循环内部）属于点对点类型的服务器，完全没有并发性可言，对于点对点的服务器来讲，一般采用阻塞IO。
	循环监听读写服务器（一台能用的服务器至少得是循环的）：
		如果将accept和close(cliefd)也加入循环，构成循环监听读写服务器，从这开始，服务器开始具备基本的并发性，在服务器的一次循环当中，服务器可以处理某个fd的某个IO事件，采用阻塞IO完全不可取，采用非阻塞IO勉强可取，这种模型适用于只有一个IO事件的短连接，但是毕竟它是以循环的方式有序同步地处理各个fd的各个IO事件，并不具备真正的并发性。
	多进程多线程服务器：
		想要让服务器具备真正的并发性，必须让服务器多进程或者多线程（这里有一个问题，多进程和多线程的适用场景，直观的看，多进程适用于不太需要通信且IO不密集型的应用，多线程恰恰相反），并发服务器一般会在为读写开一个进程或者线程，accept一般在一个单独的线程里，也可以将accept放到读写线程里，这样可大大提高并发性，应对很多用户同一时间段登录的场景，但是这需要给监听队列上锁，至于说，采用阻塞还是非阻塞，这个无关紧要，一般采用阻塞IO，非阻塞容易造成线程空转。



循环监听IO服务器的改进：
	将监听和IO分离，监听在一个线程里轮询。
	IO在一个线程里，也可以在不同的线程里：
		比如最简单的消息转发服务器就可以将IO放在一个线程里，这也是经典的【单线程非阻塞】。（错错错）
		但是一般服务器都是比较复杂的，接收到的数据往往需要经过数据处理而后进行转发，因而服务器的一般架构是：
			读线程+数据处理线程+写线程
			数据处理线程一般是使用线程池，这么做的目的是为了充分利用计算资源，而读线程和写线程可以多线程也可以单线程，一般以单线程为主，因为网络IO要比内存慢很多的，所以往往不需要使用多线程来处理IO，这也是为什么单线程非阻塞可以成为经典的read模型，尽管如此，多线程甚至线程池的IO也是可以做的，就像单线程的数据处理不行吗？当然可以，但是不好，说这些的目的是为了让自己分清楚“不行“和”不好“是两个概念。
			现在我们以最简单的消息转发为例介绍不同的IO模型：
				1单线程read+单线程write：
					最主要的IO模型（除了”单+单“，剩下的都是在一般服务器中不用的，但是为了学习，还是思考一下为好）。
					read采用单线程非阻塞，这里要注意，单线程一定得是非阻塞，阻塞是不行的，注意是不行而不是不好，如果采用阻塞，一旦某个客户端不发消息但是却不断开连接，服务器直接死锁。
					read和write之间是有一个队列的，负责存储read到的应用报文，两个线程可以采用条件变量和互斥锁机制争用这个队列	。
					消息转发是要查看包头的目的信息的，该信息的查看在write线程中。
				2多线程read+单线程write：
					多线程read分为了两种情况：
						①给每个fd开一个线程：
							这种情况我们着重要强调的是：read线程是可以使用阻塞方式的，而且阻塞方式还要比非阻塞好，因为非阻塞得用轮询，我们早就听说过一句名言”服务器开发一般是不可能使用阻塞方式读写的“，现在我们已经看到不一般的方式了，因为”服务器开发一般是不可能使用阻塞方式读写的“的内在含义其实是”服务器开发一般不用多线程IO，这个多线程IO包括给每个fd开线程和线程池“，事实是我们将会看到，线程池这种方式相比给每个fd开线程问题更大，对线程池来讲，由于其一般连接epoll，所以阻塞非阻塞已经是无所谓了，它的问题是多线程争用fd导致的同步问题。
							此时开一个队列，多个read线程和单个write线程争用它。
							目的消息在write线程里查看。
						②读线程池：
							这种方式会引发一个严重的多线程同步问题：一般我们使用epoll作为监听主程序，而非循环accept，不管是使用LT还是ET都可能会造成多个线程read一个fd的情况。
								该同步问题的解决方法就是使用ONESHOT即单次触发。
								此时使用阻塞还是非阻塞已经无所谓了。
							此时开一个队列，多个read线程和单个write线程争用它。
							目的消息的查看在write线程里。
				3单线程read+多线程write：
					read采用单线程非阻塞；
					多线程write分为了两种情况：
						①给每个fd开一个线程：
							此时如果只用一个队列，那么read线程和各个write线程将会争夺这个队列，但是问题是write线程拿到的报文中的目的fd不一定是该write线程负责的fd啊，如果不是还得转交给该包的目的fd，因而单个队列想要实现服务器，太麻烦了。
							单个队列太麻烦，给每个fd开一个写队列这样逻辑就清晰简单了，但是这样是好的方法吗？答案是否定的。想想这样做需要什么？——需要给每个写队列准备条件变量（写线程轮询的话也能用，但是轮询是不是更糟糕了？）和锁，条件变量和锁还得用一个数据结构存储以备线程们读取，这个是只读不写因而不需要使用锁了，如果这个服务器有100万条连接，那就得有100个锁和条件变量，哈哈哈，这不是在搞笑吗？
							这种情况，目的消息的查看得在read线程里。
						②写线程池：
							线程池这种技术和单线程、给每个fd开一个线程本质上不一样，不管是单线程还是给每个fd开一个线程的这种多线程其本质都是”流水线“，线程守在某个地方运行，但是线程池的本质不是”流水线“，它不针对任何专有资源比如某个队列或者某个fd，它是有工作时再开线程，没工作这个线程就销毁，为了避免频繁地创建和销毁带来的额外开销，使用条件变量和锁机制让已经创建好的线程先在条件变量上”睡着“，有工作时再”唤醒“，工作完了”接着睡“。
							写线程池就可以使用一个队列，而没有必要给每个fd创建一个写队列了，写线程池与read线程争用一个队列。
							这种情况将会出现我们在2的②中见到的多线程同步问题，而且目前我并不知道该如何解决这个问题，ONESHOT在这可不起作用了，因为epoll一般只监听read，监听write不会放在主程序中，write线程中给fd上锁可以解决该问题，此时read线程并不需要给fd上锁，因为一互斥锁并不强制二读写是两个独立行为即缓冲区互不干涉，但是这和给写队列上锁有什么区别吗？还是太低效了。							
							目的消息的查看在write线程里。
				4多线程read+多线程write：
					①给每个fd开一个read线程和一个write线程以及一个写队列；多个read线程和某个write线程争用某个写队列，这里同样会出现3的①当中出现的“一个队列一把锁”的低效问题；目的消息的查看在read线程里。（这是思路最简单的模型，也是最低效的模型）
					②线程池：相比于上面，用一个队列存储数据包，多个read线程和多个write线程争用该队列，这里同样会出现在3的②中出现的同步问题，目前除了给fd加锁这种极其低效的方法外，我并不知道怎么解决这个问题；目的消息的查看在write线程里。
			总结上述的四个服务器IO模型，我们会发现：
				34中的①往往需要创建多个写队列，而每个写队列都需要一把锁，这是极其糟糕的情况，因而像34这种IO模型基本不会出现在实际开发中。
				34中的②往往采用epoll+线程池的方式，只用一个队列，但是太多线程争用一个公共数据了，这同样也是很没有必要的，而且每个fd需要一把锁，和①比效率并没有提高，也是基本不会出现在实际开发中的。
				在34中，我们发现，②线程池的方式相比于①给每个fd开线程的方式，解决了多队列的问题但是引发了对fd的争用问题。
				2相比于34要好一点，2的①②都是一个队列，②虽然多了个对fd的争用问题，但是还是可以使用ONESHOT解决的。
				最后，1肯定是最好的，两个线程争一个队列，且不会引发对fd的多线程同步问题，唯一的问题是，有人可能觉得单线程效率有点低，事实上并不低，因为网络IO要比内存慢很多。


以上我们认识了一些IO模型，但是这些模型在实际生产中实用性不高，点对点本身就是非常少见的应用场景，循环式监听读写服务器的应用场景也非常少见且并发性不足，基于多进程多线程的服务器分为统一accept和不统一accept两种循环读写服务器，但是试想一下，如果该线程并不需要读写，此时就会阻塞在IO上或者空转，
IO多道复用机制（在企业中进行服务器开发的实际方法）：
	为了解决多进程多线程存在的问题，Linux内核为我们提供了监听代理机制，即不需要程序员在应用程序中采用阻塞或者非阻塞的方式去监听某个fd是否有数据可读或可写，而是程序员在用户态向内核注册一个监听句柄，所谓句柄就是内核的某个线程对用户提供的接口；



基于epoll的服务器模型（8种，多进程4种，多线程4种，3种是根据accept和epoll_wait这两个函数的单多分类的）：
	单线程epoll服务器，注意你给传出数组开线程池也是单线程
	统一accept，多线程epoll_wait，这里可以每一个线程wait不同的套接字描述符集合以避免同步问题
	多线程accept，这里多个线程争用一个监听队列，统一epoll_wait
	多线程epoll服务器，从accept开始就已经是多线程了